{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "%run Pipeline//upload_and_vizualize \n",
    "%run Pipeline//classify_and_evaluate \n",
    "%run Pipeline//aux\n",
    "%run Pipeline//ULAB_ML_Pipeline\n",
    "%run processing\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import sys\n",
    "import random\n",
    "import sklearn as sk \n",
    "import json \n",
    "import re\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "from time import time\n",
    "from sklearn import svm, ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit, RandomizedLogisticRegression\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.cross_validation import train_test_split, KFold\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.grid_search import ParameterGrid\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import *\n",
    "import csv\n",
    "from errno import EEXIST\n",
    "from os import makedirs,path\n",
    "from datetime import datetime as dr\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "import pylab as pl\n",
    "from upload_and_vizualize import camel_to_snake\n",
    "from datetime import datetime as dt\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### SHOULD BE WITHIN CLEANING.PY ###\n",
    "\n",
    "## FROM PREPROCESSING ##\n",
    "\n",
    "#interest_var = ['PGM_SYS_ID','ACTIVITY_ID','AGENCY_TYPE_DESC','STATE_CODE','AIR_LCON_CODE','COMP_DETERMINATION_UID','ENF_RESPONSE_POLICY_CODE','PROGRAM_CODES']\n",
    "def replace_with_value(data_file, variables, values):\n",
    "    '''\n",
    "    '''\n",
    "    for variable in variables:\n",
    "        value = values[variables.index(variable)]\n",
    "        data_file[variable] = data_file[variable].fillna(value)\n",
    "\n",
    "def convert_to_datetime(series_row, date_format):\n",
    "    if str(series_row) == 'nan':\n",
    "        return float('nan')\n",
    "    return dt.strptime(series_row, date_format)\n",
    "\n",
    "def convert_to_year(series_row):\n",
    "    if str(series_row) == 'NaT' or str(series_row)== 'nan':\n",
    "        return float('nan')\n",
    "    else:\n",
    "        return str(series_row.year)\n",
    "\n",
    "def to_date_time(df, date_format, date_col):\n",
    "    #add datetime column\n",
    "    df[date_col+'_datetime'] = df[date_col].apply(convert_to_datetime, date_format=date_format)\n",
    "    df[date_col+'_year'] = df[date_col+'_datetime'].apply(convert_to_year)\n",
    "\n",
    "    #return df\n",
    "\n",
    "def convert_to_month(series_row):\n",
    "    if str(series_row) == 'NaT' or str(series_row)== 'nan':\n",
    "        return float('nan')\n",
    "    else:\n",
    "        return str(series_row.month)\n",
    "\n",
    "def get_month_year_col(df, date_column, date_format):\n",
    "    df[date_column+'_datetime'] = df[date_column].apply(convert_to_datetime, date_format=date_format)\n",
    "    df[date_column+'_month'] = df[date_column+'_datetime'].apply(convert_to_month)\n",
    "    df[date_column+'_year'] = df[date_column+'_datetime'].apply(convert_to_year)\n",
    "    return df\n",
    "\n",
    "def filter_date(df, date_format, date_col, start=None, end=None):\n",
    "    to_date_time(df, date_format, date_col)\n",
    "    \n",
    "    \n",
    "    if start:\n",
    "        timestart = dt.strptime(start,\"%Y/%m/%d\")\n",
    "        #print(start)\n",
    "        df = df[df[date_col+'_datetime'] >= timestart ]\n",
    "        #print(df.head())\n",
    "    if end:\n",
    "        timeend = dt.strptime(end,\"%Y/%m/%d\")\n",
    "        #print(end)\n",
    "        df = df[df[date_col+'_datetime'] <= timeend ]\n",
    "        #print(df.head())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def filter_col(df, fac_id, features, date_col):\n",
    "    #filter needed\n",
    "    df = df[[fac_id] + [date_col+'_datetime'] + [date_col+'_year'] + features]\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## FROM PREPROCESSING, MODIFIED ##\n",
    "def add_dummy(df, variable_list, sep_char = None, drop_one=False, drop_original=False):\n",
    "    '''\n",
    "    Input: \n",
    "        - df: pandas dataframe\n",
    "        - variable_list: a list of variables to dummitize\n",
    "        - drop_one: whether to drop first dummy\n",
    "        - drop_original: whether to drop original categorical variable\n",
    "    Output: dataframe with tht dummy variables added\n",
    "    '''\n",
    "    for variable in variable_list:\n",
    "        if sep_char:\n",
    "            df_dummy = df[variable].str.get_dummies(sep=sep_char)\n",
    "            df_dummy.columns = [variable+ '_' +str(col) for col in df_dummy.columns]\n",
    "\n",
    "        else:\n",
    "            df_dummy = pd.get_dummies(df[variable], drop_first=drop_one, prefix = variable)\n",
    "        \n",
    "        df = pd.concat([df, df_dummy], axis=1)\n",
    "        if drop_original:\n",
    "            df = df.drop(variable, 1)\n",
    "    return (df, df_dummy.columns)\n",
    "\n",
    "def aggr_dummy_cols(df, final_df, colnames, mode = None):\n",
    "    for col in colnames:\n",
    "        \n",
    "        cross = pd.crosstab(df['id_+_date'], columns=df[col])\n",
    "        \n",
    "        if mode == 'cat':\n",
    "            cross.columns = [cross.columns.name+ '_' +str(col) for col in cross.columns]\n",
    "        \n",
    "        elif mode == 'dum':\n",
    "            cross = cross.drop(0, axis = 1)\n",
    "            cross.columns = [cross.columns.name for col in cross.columns]\n",
    "            \n",
    "        #SIMPLIFY THIS!!\n",
    "        elif mode == 'bim':\n",
    "            cross = cross.drop('N', axis = 1)\n",
    "            cross.columns = [cross.columns.name for col in cross.columns]\n",
    "        \n",
    "        #ADD PROCESSING CONT_VAR\n",
    "        \n",
    "        else:\n",
    "            cross.columns = [cross.columns.name for col in cross.columns]\n",
    "            \n",
    "        cross.columns.name = None\n",
    "        cross.reset_index(inplace=True)\n",
    "        \n",
    "        \n",
    "        if final_df.empty:\n",
    "            final_df = final_df.append(cross)\n",
    "        else:\n",
    "            final_df = pd.merge(final_df, cross, how = 'left', on = 'id_+_date')\n",
    "            \n",
    "    return final_df\n",
    "\n",
    "## FROM ULAB PIPELINE ##\n",
    "\n",
    "def generate_continous_variable(data_file, variable_list):\n",
    "    '''\n",
    "    function that can take a categorical variable and create \n",
    "    binary variables from it\n",
    "    '''\n",
    "    for variable in variable_list:\n",
    "        list_values = list(data_file.groupby(variable).groups.keys())\n",
    "        for i,value in enumerate(list_values):\n",
    "            data_file[variable].replace(value,i)\n",
    "\n",
    "    return data_file \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "FACILITY = 'data/ICIS-AIR_downloads/ICIS-AIR_FACILITIES.csv'\n",
    "VIOLATION = 'data/ICIS-AIR_downloads/ICIS-AIR_VIOLATION_HISTORY.csv'\n",
    "INSPECTION = 'data/ICIS-AIR_downloads/ICIS-AIR_FCES_PCES.csv'\n",
    "FORMALACT = 'data/ICIS-AIR_downloads/ICIS-AIR_FORMAL_ACTIONS.csv'\n",
    "INFORMALACT = 'data/ICIS-AIR_downloads/ICIS-AIR_INFORMAL_ACTIONS.csv'\n",
    "STACKTEST = 'data/ICIS-AIR_downloads/ICIS-AIR_STACK_TESTS.csv'\n",
    "TITLEV = 'data/ICIS-AIR_downloads/ICIS-AIR_TITLEV_CERTS.csv'\n",
    "\n",
    "#facilities = read_file('ICIS-AIR_downloads/ICIS-AIR_FACILITIES.csv')\n",
    "#pd_violations = read_file('ICIS-AIR_downloads/ICIS-AIR_VIOLATION_HISTORY.csv')\n",
    "#pd_inspection = read_file('ICIS-AIR_downloads/ICIS-AIR_FCES_PCES.csv')\n",
    "#pd_formalact = read_file('ICIS-AIR_downloads/ICIS-AIR_FORMAL_ACTIONS.csv')\n",
    "#pd_informalact = read_file('ICIS-AIR_downloads/ICIS-AIR_INFORMAL_ACTIONS.csv')\n",
    "#pd_stacktest = read_file('ICIS-AIR_downloads/ICIS-AIR_STACK_TESTS.csv')\n",
    "#pd_titlev = read_file('ICIS-AIR_downloads/ICIS-AIR_TITLEV_CERTS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## CONFIG DATA ##\n",
    "START_DATE= '2007/01/01'\n",
    "END_DATE = '2016/12/31'\n",
    "fac_id = 'PGM_SYS_ID'\n",
    "df_dict ={'violation': {#'data_file': 'data/ICIS-AIR_downloads/ICIS-AIR_VIOLATION_HISTORY.csv',\n",
    "                        'interest_var': ['AGENCY_TYPE_DESC','AIR_LCON_CODE','ENF_RESPONSE_POLICY_CODE','POLLUTANT_CODES','PROGRAM_CODES','HPV_RESOLVED_DATE'],\n",
    "                         'date_col': 'HPV_DAYZERO_DATE',\n",
    "                       'date_format':'%m-%d-%Y'},\n",
    "          \n",
    "           'inspection': {'interest_var': ['STATE_EPA_FLAG','COMP_MONITOR_TYPE_CODE','PROGRAM_CODES'],\n",
    "                         'date_col': 'ACTUAL_END_DATE',\n",
    "                         'date_format':'%m-%d-%Y'},\n",
    "          \n",
    "           'stacktest': {'interest_var':['COMP_MONITOR_TYPE_CODE','POLLUTANT_CODES','AIR_STACK_TEST_STATUS_CODE'],\n",
    "                        'date_col': 'ACTUAL_END_DATE',\n",
    "                        'date_format':'%m/%d/%Y'},\n",
    "          \n",
    "           'titlev':{'interest_var':['COMP_MONITOR_TYPE_CODE','FACILITY_RPT_DEVIATION_FLAG'],\n",
    "                        'date_col': 'ACTUAL_END_DATE',\n",
    "                    'date_format':'%m/%d/%Y'},\n",
    "          \n",
    "           'formalact':{'interest_var':['ENF_TYPE_CODE','PENALTY_AMOUNT'],\n",
    "                        'date_col': 'SETTLEMENT_ENTERED_DATE',\n",
    "                       'date_format':'%m/%d/%Y'},\n",
    "          \n",
    "           'informalact':{'interest_var':['ENF_TYPE_CODE'],\n",
    "                        'date_col': 'ACHIEVED_DATE',\n",
    "                         'date_format':'%m/%d/%Y'}}\n",
    "\n",
    "#general_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## READ INITIAL FILTERED FILE ##\n",
    "violation, inspection, titlev, stacktest, formalact, informalact = general_read_file(df_dict, START_DATE, END_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "violation = read_file('data/ICIS-AIR_downloads/ICIS-AIR_VIOLATION_HISTORY.csv')\n",
    "inspection = read_file('data/ICIS-AIR_downloads/ICIS-AIR_FCES_PCES.csv')\n",
    "date_types = ['year']\n",
    "date_format ='%m-%d-%Y'\n",
    "date_col = ['HPV_DAYZERO_DATE','HPV_RESOLVED_DATE','EARLIEST_FRV_DETERM_DATE']\n",
    "get_occupied_frame(violation,date_col,date_format,date_types)\n",
    "\n",
    "date_col = ['ACTUAL_END_DATE']\n",
    "get_occupied_frame(inspection,date_col,date_format,date_types)\n",
    "\n",
    "fce = inspection[['PGM_SYS_ID','STATE_EPA_FLAG','COMP_MONITOR_TYPE_CODE','PROGRAM_CODES','ACTUAL_END_DATE','ACTUAL_END_DATE_year','ACTUAL_END_DATE_datetime']]\n",
    "violation = violation[['PGM_SYS_ID','AGENCY_TYPE_DESC','AIR_LCON_CODE','ENF_RESPONSE_POLICY_CODE','POLLUTANT_CODES','PROGRAM_CODES','HPV_DAYZERO_DATE','HPV_DAYZERO_DATE_year','HPV_DAYZERO_DATE_datetime']]\n",
    "violation = violation[violation.ENF_RESPONSE_POLICY_CODE == 'HPV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_features(start_date, end_date):\n",
    "    #violation, inspection, titlev, stacktest, formalact, informalact = general_read_file(df_dict, START_DATE, END_DATE)\n",
    "    \n",
    "    violation_df = process_violation(violation, start_date, end_date)\n",
    "    inspection_df = process_titlev(titlev, start_date, end_date)\n",
    "    stacktest_df = process_stacktest(stacktest, start_date, end_date)\n",
    "    formalact_df = process_formalact(formalact, start_date, end_date)\n",
    "    informalact_df = process_informalact(informalact, start_date, end_date)\n",
    "    noninspectHPV_df = process_noninspectHPV(violation, inspection, start_date, end_date)\n",
    "    \n",
    "    final_df = pd.merge(inspection_df, violation_df, how = 'left', right_on = [\"id_+_date\"], left_on = [\"id_+_date\"])\n",
    "    final_df = pd.merge(final_df, stacktest_df, how = 'left', right_on = [\"id_+_date\"], left_on = [\"id_+_date\"])\n",
    "    final_df = pd.merge(final_df, formalact_df, how = 'left', right_on = [\"id_+_date\"], left_on = [\"id_+_date\"])\n",
    "    final_df = pd.merge(final_df, informalact_df, how = 'left', right_on = [\"id_+_date\"], left_on = [\"id_+_date\"])\n",
    "    final_df = pd.merge(final_df, noninspectHPV_df, how = 'left', right_on = [\"id_+_date\"], left_on = [\"id_+_date\"])\n",
    "\n",
    "    re_separate = r'(.[^_]*)_(.*)'\n",
    "    sep = lambda x: pd.Series([i for i in re.split(re_separate,x)])\n",
    "    final_id_year = final_df['id_+_date'].apply(sep)\n",
    "    final_df =pd.concat([final_id_year.rename(columns={1:'PGM_SYS_ID',2:'HPV_DAYZERO_DATE_year'}), final_df], axis=1)\n",
    "    final_df.drop([0, 3, 'id_+_date'], axis = 1, inplace = True)\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56246, 173)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for feature generation\n",
    "start_date = '2009'\n",
    "end_date = '2012'\n",
    "feat = generate_features(start_date, end_date)\n",
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PGM_SYS_ID</th>\n",
       "      <th>HPV_DAYZERO_DATE_datetime</th>\n",
       "      <th>HPV_DAYZERO_DATE_year</th>\n",
       "      <th>AGENCY_TYPE_DESC</th>\n",
       "      <th>AIR_LCON_CODE</th>\n",
       "      <th>ENF_RESPONSE_POLICY_CODE</th>\n",
       "      <th>POLLUTANT_CODES</th>\n",
       "      <th>PROGRAM_CODES</th>\n",
       "      <th>HPV_RESOLVED_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CT0000000900508907</td>\n",
       "      <td>2010-03-17</td>\n",
       "      <td>2010</td>\n",
       "      <td>State</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HPV</td>\n",
       "      <td>300000329</td>\n",
       "      <td>CAAFESOP</td>\n",
       "      <td>11-02-2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CT0000000900100078</td>\n",
       "      <td>2007-08-08</td>\n",
       "      <td>2007</td>\n",
       "      <td>State</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HPV</td>\n",
       "      <td>300000329</td>\n",
       "      <td>CAAFESOP</td>\n",
       "      <td>09-24-2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CT0000000901501125</td>\n",
       "      <td>2013-04-26</td>\n",
       "      <td>2013</td>\n",
       "      <td>State</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HPV</td>\n",
       "      <td>10193</td>\n",
       "      <td>CAATVP</td>\n",
       "      <td>06-25-2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CT0000000900109058</td>\n",
       "      <td>2008-01-17</td>\n",
       "      <td>2008</td>\n",
       "      <td>State</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HPV</td>\n",
       "      <td>300000005</td>\n",
       "      <td>CAAFESOP</td>\n",
       "      <td>01-06-2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CT0000000901100054</td>\n",
       "      <td>2008-04-08</td>\n",
       "      <td>2008</td>\n",
       "      <td>State</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HPV</td>\n",
       "      <td>10461 300000005</td>\n",
       "      <td>CAATVP</td>\n",
       "      <td>12-10-2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PGM_SYS_ID HPV_DAYZERO_DATE_datetime HPV_DAYZERO_DATE_year  \\\n",
       "5   CT0000000900508907                2010-03-17                  2010   \n",
       "6   CT0000000900100078                2007-08-08                  2007   \n",
       "7   CT0000000901501125                2013-04-26                  2013   \n",
       "9   CT0000000900109058                2008-01-17                  2008   \n",
       "13  CT0000000901100054                2008-04-08                  2008   \n",
       "\n",
       "   AGENCY_TYPE_DESC AIR_LCON_CODE ENF_RESPONSE_POLICY_CODE  POLLUTANT_CODES  \\\n",
       "5             State           NaN                      HPV        300000329   \n",
       "6             State           NaN                      HPV        300000329   \n",
       "7             State           NaN                      HPV            10193   \n",
       "9             State           NaN                      HPV        300000005   \n",
       "13            State           NaN                      HPV  10461 300000005   \n",
       "\n",
       "   PROGRAM_CODES HPV_RESOLVED_DATE  \n",
       "5       CAAFESOP        11-02-2010  \n",
       "6       CAAFESOP        09-24-2009  \n",
       "7         CAATVP        06-25-2014  \n",
       "9       CAAFESOP        01-06-2009  \n",
       "13        CAATVP        12-10-2008  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "violation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### FAILED LABEL #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_label(violhist, fce, start_year, end_year):\n",
    "    #removing FRVs\n",
    "    #violhist = violhist[violhist.ENF_RESPONSE_POLICY_CODE != 'FRV']\n",
    "    violhist = violhist[violhist['HPV_DAYZERO_DATE_year'] >= start_year]\n",
    "    violhist = violhist[violhist['HPV_DAYZERO_DATE_year'] <= end_year]\n",
    "    \n",
    "    #for fce\n",
    "    fce = fce[fce['ACTUAL_END_DATE_year'] >= start_year]\n",
    "    fce = fce[fce['ACTUAL_END_DATE_year'] <= end_year]\n",
    "    \n",
    "    merged_hpv_fce = pd.merge(violhist, fce, how='right', left_on=['PGM_SYS_ID', 'HPV_DAYZERO_DATE'], right_on=['PGM_SYS_ID','ACTUAL_END_DATE'])\n",
    "    \n",
    "    #finding 0's\n",
    "    '''\n",
    "    non_viol = merged_hpv_fce[merged_hpv_fce.HPV_DAYZERO_DATE.isnull()]\n",
    "    non_viol['is_violation'] = 0\n",
    "    '''\n",
    "    #non_viol = merged_hpv_fce\n",
    "    #non_viol.HPV_DAYZERO_DATE.fillna(0, inplace=True)\n",
    "    #non_viol = non_viol.filter(['PGM_SYS_ID', 'ACTUAL_END_DATE', 'is_violation', 'ACTUAL_END_DATE_year'], axis = 1)\n",
    "    #***non_viol = non_viol[['PGM_SYS_ID', 'ACTUAL_END_DATE', 'ACTUAL_END_DATE_year']]\n",
    "    #non_viol.rename(columns={'ACTUAL_END_DATE': 'HPV_DAYZERO_DATE', 'ACTUAL_END_DATE_year': \"HPV_DAYZERO_DATE_year\" }, inplace=True)\n",
    "    #finding 1's\n",
    "    #viol = merged_hpv_fce[merged_hpv_fce.HPV_DAYZERO_DATE.notnull()]\n",
    "    #***viol = merged_hpv_fce\n",
    "    #***viol.HPV_DAYZERO_DATE.fillna(0, inplace=True)\n",
    "    #viol['is_violation'] = 1\n",
    "    #viol = viol.filter(['PGM_SYS_ID', 'HPV_DAYZERO_DATE', 'is_violation', 'HPV_DAYZERO_DATE_year'], axis = 1)\n",
    "    #***viol = viol[['PGM_SYS_ID', 'HPV_DAYZERO_DATE', 'HPV_DAYZERO_DATE_year']]\n",
    "    #***output = pd.concat([viol,non_viol])\n",
    "    #output['id_+_date'] = output.PGM_SYS_ID +'_'+ output.HPV_DAYZERO_DATE_year\n",
    "    #output.drop(['PGM_SYS_ID', 'HPV_DAYZERO_DATE', 'HPV_DAYZERO_DATE_year'], axis = 1, inplace = True)\n",
    "    #output = output.groupby('id_+_date').size().reset_index()\n",
    "    #output.rename(columns = {0:\"outcome\"}, inplace = True)\n",
    "    #return output\n",
    "    return merged_hpv_fce, violhist, fce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out, violhist, fce = generate_label(violation, inspection, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PGM_SYS_ID</th>\n",
       "      <th>AGENCY_TYPE_DESC</th>\n",
       "      <th>AIR_LCON_CODE</th>\n",
       "      <th>ENF_RESPONSE_POLICY_CODE</th>\n",
       "      <th>POLLUTANT_CODES</th>\n",
       "      <th>PROGRAM_CODES</th>\n",
       "      <th>HPV_DAYZERO_DATE</th>\n",
       "      <th>HPV_DAYZERO_DATE_year</th>\n",
       "      <th>HPV_DAYZERO_DATE_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CT0000000900700108</td>\n",
       "      <td>State</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HPV</td>\n",
       "      <td>300000005 300000323</td>\n",
       "      <td>CAASIP</td>\n",
       "      <td>05-28-1996</td>\n",
       "      <td>1996</td>\n",
       "      <td>1996-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CT0000000900900110</td>\n",
       "      <td>State</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HPV</td>\n",
       "      <td>300000005 300000323</td>\n",
       "      <td>CAASIP</td>\n",
       "      <td>05-28-1996</td>\n",
       "      <td>1996</td>\n",
       "      <td>1996-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CT0000000900900110</td>\n",
       "      <td>State</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HPV</td>\n",
       "      <td>10461 300000005</td>\n",
       "      <td>CAASIP</td>\n",
       "      <td>08-21-1998</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998-08-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CT0000000900300125</td>\n",
       "      <td>State</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HPV</td>\n",
       "      <td>300000242 300000329</td>\n",
       "      <td>CAASIP</td>\n",
       "      <td>07-12-2005</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005-07-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CT0000000900508907</td>\n",
       "      <td>State</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HPV</td>\n",
       "      <td>300000329</td>\n",
       "      <td>CAAFESOP</td>\n",
       "      <td>03-17-2010</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-03-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           PGM_SYS_ID AGENCY_TYPE_DESC AIR_LCON_CODE ENF_RESPONSE_POLICY_CODE  \\\n",
       "0  CT0000000900700108            State           NaN                      HPV   \n",
       "2  CT0000000900900110            State           NaN                      HPV   \n",
       "3  CT0000000900900110            State           NaN                      HPV   \n",
       "4  CT0000000900300125            State           NaN                      HPV   \n",
       "5  CT0000000900508907            State           NaN                      HPV   \n",
       "\n",
       "       POLLUTANT_CODES PROGRAM_CODES HPV_DAYZERO_DATE HPV_DAYZERO_DATE_year  \\\n",
       "0  300000005 300000323        CAASIP       05-28-1996                  1996   \n",
       "2  300000005 300000323        CAASIP       05-28-1996                  1996   \n",
       "3      10461 300000005        CAASIP       08-21-1998                  1998   \n",
       "4  300000242 300000329        CAASIP       07-12-2005                  2005   \n",
       "5            300000329      CAAFESOP       03-17-2010                  2010   \n",
       "\n",
       "  HPV_DAYZERO_DATE_datetime  \n",
       "0                1996-05-28  \n",
       "2                1996-05-28  \n",
       "3                1998-08-21  \n",
       "4                2005-07-12  \n",
       "5                2010-03-17  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "violation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out.HPV_DAYZERO_DATE.fillna(0, inplace=True)\n",
    "\n",
    "def change_to_zero(series_row):\n",
    "    if type(series_row) != str:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "out['Outcome'] = out.HPV_DAYZERO_DATE.apply(change_to_zero)\n",
    "#test = out.HPV_DAYZERO_DATE_year.replace(~0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    290159\n",
       "1      1839\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.Outcome.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_ay = out.groupby(['PGM_SYS_ID', 'ACTUAL_END_DATE_year']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def change_to_zero_float(series_row):\n",
    "    if series_row > 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "output_ay.Outcome = output_ay.Outcome.apply(change_to_zero_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2009    37380\n",
       "2011    36210\n",
       "2012    36007\n",
       "2010    35867\n",
       "Name: ACTUAL_END_DATE_year, dtype: int64"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ay.ACTUAL_END_DATE_year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
